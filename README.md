
# Back-End Challenge

This is a back-end challenge for Instabug's hiring process.  

Creating an API for an application-chatting system, similar to help chat in some websites.

Each application would act as a website, as each website would have many chats for each user, and each chat would have many messages.

We could reach the application via some unique token generated by the system and returned upon creation.
We then could reach the chats in each application via its application's token and its chat number specific to that application, which is also returned on creation.

Additional optimizations shall be implemented, like preventing race conditions in case of multiple servers running in parallel with multiple concurrent requests.  
Also adding indices for more performance, minimizing SQL queries while serving requests.

We shall also provide a searching feature where a client can search in the messages of a specific chat for some keyword, the search shall return partial matches along with exact matches.

# Environment:
- Ruby v2.5.1
- Rails v5.2.8
- Mysql v5.7
- Redis v4.2
- Sidekiq v6.4.1
- Searchkick v4.6.3
- Docker v20.10.14

## Run Locally

Clone the project

```bash
  git clone https://github.com/HeshamaMohamed/Chat-System
```

Go to the project directory

```bash
  cd Chat-System
```

Start docker container

```bash
  docker-compose up
```
# API Reference

## Application API

#### Get all applications

```http
GET /api/v1/applications
```

#### Show a specific application

```http
GET /api/v1/applications/:token
```
#### Create an application

```http
POST /api/v1/applications
```

#### Update a specific application

```http
PATCH /api/v1/applications/:token?name=AppNewName
```
## Chats API

#### Get all Chats in an application

```http
GET /api/v1/applications/:application_token/chats
```

#### Show a specific chat in an application

```http
GET /api/v1/applications/:application_token/chats/:chat_number
```

#### Create a chat in an application

```http
POST /api/v1/applications/:application_token/chats/
```

#### Search a specific chat in an application

```http
POST /api/v1/applications/:application_token/chats/:chat_number/search?query='message'
```

## Messages API

#### Get all Messages in a chat

```http
GET /api/v1/applications/:application_token/chats/:chat_number/messages
```

#### Show a specific message in a chat

```http
GET /api/v1/applications/:application_token/chats/:chat_number/messages/:message_number
```

#### Create a message in a chat

```http
POST /api/v1/applications/:application_token/chats/:chat_number/messages
```

#### Update a specific message in a chat

```http
PATCH /api/v1/applications/:application_token/chats/:chat_number/search?query='message'
```

# Documentation of Implementation Decisions, Challenges, and learning.

## DISCLAIMER: This section is a bit long. but It covers most of what I have thought about while implementing this.  


  This task was treated as a learning project in which I am happy with the actual learning outcome.  
  This would act as a future self-reference for my current analysis/development level.
  Therefore, I will be documenting what I can recall from the learning journey and decision-making process (what and why).  
  That includes the decisions I have taken, the decisions I took and implemented at first but gave up on it later for better options,  
  and the decisions I thought of taking but found out it was not a good choice.

  One thing that helped me very much while Developing this system was: analyzing and designing it all as much as I can before writing any code.  
  I have tried doing that before as I read how important it is. But, every time I came across a coding challenge/problem, I found myself writing code before I knew it.
It helped me organize the implementation process and divide it into specific sub-tasks.  
  Also, that helped me identify the challenges I might face implementing some of the features.  
  Along with thinking of various solutions and comparing them to decide which is the better option.

## Indexing, rails composite foreign keys, and composite primary keys
### The DB indexing part was a bit challenging.  
First, finding an app by its token made it clear that I need to create a unique index for the token.  
Similarly, the chats table needed a unique index on the chat_number specific to each application_token.  
Similarly, the messages table needed a unique index on the message_number specific to each chat.

### Creating associations with composite foreign keys:
We had to specify the foreign key of the application model as the token rather than the id.  
The message model was a bit tricky since we needed to reference a composite foreign key in the chats table (application_token, chat_number).  
Rails association by default doesn't support multi-column reference. So, I found a cool gem that helped me implement that.  
[composite_primary_keys gem](https://github.com/composite-primary-keys/composite_primary_keys)
  
  - (implemented then discarded): I customized the has_many and belongs_to associations between chats and messages to guarantee that our queries utilize our index as a covering index.  
    I left the implementation code commented out.  
    ActiveRecord migration doesn't support the creation of composite foreign keys, I had to customize it with raw SQL.

  - (To experiment later) while searching for ways to implement a composite index via ActiveRecord, I stumbled upon this article,  
    [How to introduce composite primary keys in rails](https://shopify.engineering/how-to-introduce-composite-primary-keys-in-rails)  
    The article highlighted something I wasn't aware of. What if I should use a composite primary key instead of a normal composite index.  
    After reading about the difference between a composite unique index and composite primary keys,  
    I learned that a composite primary key is faster because it is a clustered index.  
    However, I had to take into consideration the downside mentioned in the article (more expensive insertions).  
    
    So, a choice has to be made. Implementing a unique composite index to keep the insertion fast and give up extra reading performance,  
    or implementing a composite primary key that improves reading performance at the cost of slower insertions.  
    Since the problem statement says "It is allowed for chats and messages to take time to be persisted",  
    I take from it that insertions performance isn't as important as reading performance.  
    I will experiment with this later though to see how much performance improvement we can get.

### counters and race conditions.
There are a couple of race conditions presented. 2 of them which are visible to me are:  
1 - Multiple concurrent message creation requests could mess up the order of messages in the same chat.  
2 - Multiple concurrent Chats and Messages creation requests could mess up the chats_counter/messages_counter values.  
Based on Number 2, two or more chats/messages being created with the same number and same token id would lead to an error due to the unique index constraint.  

we need to handle each, so;  
1 - We make a queue to handle the order of message/chat creation and also increment counters (Using Sidekiq).  
2 - We ensure operation atomicity regarding the incrementing of counters (Using Redis INCR) before sending creation requests to queues.  

- (Not Implemented) As for number 2, I thought of incrementing the counters in the queue along with chat/message creation at first for two reasons.  
    avoid the need for atomic increment operation since the queue would avoid race conditions specific to counters as well.  
    have consistency between the number of current records persisted in DB and the actual counter value cached.  
    
    However, since we needed to return the actual counter value (chat/message number) immediately on creation for objects that have yet to be persisted to DB, we needed to increment the counters on creation before the actual records persist in the database.  

- (Not Implemented) Splitting queues.
    I thought of splitting the creation of messages and chats into 2 separate queues where the work is distributed evenly among them.  
    Thankfully, I didn't. This would have presented a race condition where we could have tried to request to create a message for a chat that was not yet created.  
    I also thought of setting the priority to the chat creation queue to prevent that race condition.  
    However, there was no actual need for all of that as letting both of them in the same queue would also prevent the race condition.  

- scheduling a periodic update of counters to DB (Using Sidekiq-scheduler).  
    I have found several job scheduling gems, I chose sidekiq-scheduler.  
    I tried implementing the update using ActiveRecords#update for each application but found it inefficient while observing the queries called on the server. It was an n+1 query problem.  
    It got even worse with chats as its number is greater than that of apps.  
    Then I tried the ActiveRecords#update_all method to make it a single query and it worked.  
    However, I also tried updating it with raw SQL without using the ORM at all. The performance gain with a few applications and chats was like 2x, despite although it executes the same query as the ORM.  
    No idea why executing the same query through the ORM was slower, but I did it with raw SQL anyway.  
    I had the raw SQL insight from this article 
    [Proper Counter cache migrations in rails](http://ryan.mcgeary.org/2016/02/05/proper-counter-cache-migrations-in-rails)


- (Not implemented) -- rails counter cache.  
    although the problem statement says "These columns don’t have to be live. However, they shouldn’t be lagging more than 1 hour", it would be better to make them live if it has little to no performance cost.  
    especially if we have sacrificed the 'live' values for performance improvement in the first place.  
    I remember reading about counter caching in rails, so I went to check it out.  
    Comparing it to the Redis/sidekiq approach, it is a little more expensive in regards to writing queries, as it updates the counter with each insertion.  
    But, it doesn't query the count() of the table each time to update the parent table counter, it updates it from the cache just like Redis.  
    And it would also store the value counter in a cache, with no queries needed to get the value.  
    I don't know how the update queries per insertion would affect the performance. But I thought it is simpler and would remove the layer of complexity of using Redis and sidekiq to achieve that.  
    However, I didn't go on with that as I have read it is slower compared to the Redis caching approach, and performance comes first.  
    
- (Not implemented) -- Database auto_increment for chat_number/message_number.  
    Thinking about the chat_number, message_number race condition, I wondered, can't I just use MySQL's auto_increment on chat_number/message_number instead of having to risk wrong value insertion.  
    I searched for how to implement auto_increment on a secondary key of a composite index (chats_number in (app_token, chats_number) index).  
    I found a way that shows how to implement it in MySQL documentation.  [Mysql Example auto increment](https://dev.mysql.com/doc/refman/8.0/en/example-auto-increment.html)  
    Having to use MyISAM as the DB engine for the tables implementing this, I had to learn about its implications.  
    Most of what I have read has discouraged me from selecting that approach.  
    I have read about the limitations of MyISAM Engine regarding transactions, row-locking, and how it is not the default MySQL engine anymore.  
    So, I got a bit skeptical about it being the best choice, and I decided to stick with the caching option via REDIS.  


### Searching messages using Elastic Search  
I haven't used elastic search before. I found a few gems integrating it in ruby. as I read about them and a couple of Stackoverflow posts on the topic,
I settled with Searchkick as it is more Rails-friendly and also more popular according to [searchkick vs elasticsearch-rails](https://ruby.libhunt.com/compare-searchkick-vs-elasticsearch-rails.)

