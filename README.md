
## Creating an API for an application-chatting system, similar to the chatbots implemented in web applications.
### Brief Explanation

Each application would have many chats for each visitor, and each chat would have many messages.

We could reach the application via some unique token generated by the system and returned upon creation.  
We then could reach the chats in each application via its application's token and its chat number specific to that application.  
The chat number is also returned upon chat creation.

Applications need to store the number of chats they have got, as the chats need to store the number of messages they have got.

We shall also provide a searching feature where a client can search in the messages of a specific chat for some query, the search shall return partial matches along with exact matches.

Additional optimizations shall be implemented, some of them are:
- preventing race conditions in case of multiple servers running in parallel with multiple concurrent requests.
- Adding relevant indices in DB for more performance.
- Minimizing SQL queries while serving requests.

# Environment:
- Ruby v2.5.1
- Rails v5.2.8
- Mysql v5.7
- Redis v4.2
- Sidekiq v6.4.1
- Searchkick v4.6.3
- Docker v20.10.14

## Run Locally

Clone the project

```bash
git clone https://github.com/HeshamaMohamed/Chat-System
```

Go to the project directory

```bash
cd Chat-System
```

Start docker container

```bash
docker-compose up
```
# API Reference

## Application API

#### Get all applications

```http
GET /api/v1/applications
```

#### Show a specific application

```http
GET /api/v1/applications/:token
```
#### Create an application

```http
POST /api/v1/applications?name=NewAppName
```

#### Update a specific application

```http
PATCH /api/v1/applications/:token?name=ModifiedAppName
```
## Chats API

#### Get all Chats in an application

```http
GET /api/v1/applications/:application_token/chats
```

#### Show a specific chat in an application

```http
GET /api/v1/applications/:application_token/chats/:chat_number
```

#### Create a chat in an application

```http
POST /api/v1/applications/:application_token/chats/
```

#### Search a specific chat in an application

```http
POST /api/v1/applications/:application_token/chats/:chat_number/search?query='message'
```

## Messages API

#### Get all Messages in a chat

```http
GET /api/v1/applications/:application_token/chats/:chat_number/messages
```

#### Show a specific message in a chat

```http
GET /api/v1/applications/:application_token/chats/:chat_number/messages/:message_number
```

#### Create a message in a chat

```http
POST /api/v1/applications/:application_token/chats/:chat_number/messages?body=NewMessageBody
```

#### Update a specific message in a chat

```http
PATCH /api/v1/applications/:application_token/chats/:chat_number/messages/:message_number?body=ModifiedMessageBody
```

# Documentation of challenges, design decisions, and lessons learned.

## DISCLAIMER: This section is a bit long. but It covers most of my thought process while designing and implementing this.  

  This project was treated as a learning project in which I am happy with the actual learning outcome.  
  For me, it would act as a future self-reference for my current analysis/development level.  
  
  Therefore, I will be documenting what I can recall from the learning journey and decision-making process (what and why).  
  This includes the decisions I made, the decisions I made and discarded for better options, and the decisions I thought to make, but wasn't good choice.

## Planning/Analysis and design.
  One thing that helped me very much while Developing this system was: **Analyzing and designing it all as much as I can before writing any code.**  
  I have tried doing this many times in the past as I have read how important it is.  
  But unfortunately, every time I faced a coding challenge, I found myself starting to write code before I knew it.
  
  Having tried that successfully now, helped me organize the implementation process.  
  Also, that helped me identify the challenges I might face implementing some of the features.  
  Along with thinking of various solutions and comparing them to decide which is the better option.  
  
  This has benefited me in more ways than I can imagine, some of which I can think of and mention are:
  - It avoided me from wasting so much time, walking paths that I would eventually not select as it is not the perfect fit.  
  - It helped me organize the implementation process and divide it into specific sub-tasks, and that lead to:
    - Better ordering of the tasks based on the task dependencies.
    - Eliminating the "What now?" moments that I usually get when developing anything after completing any part.
    - Eliminated the constant context switching between developing and designing state of mind that would cause distraction and overhead.
    - Having some sort of time estimation, I was able to give a rough estimation of each specific sub-task, summing all those estimations to get a rough estimation of the whole project.
  
  Having all of the above benefits, I had a more comfortable developing process and a quality learning experience.

## Indexing, rails composite foreign keys, and composite primary keys
### DB indexing  
Finding an application by its token made it clear that I need to create a unique index for the token.  
Similarly, the chats table needed a unique index on the chat_number specific to each application_token.  
Similarly, the messages table needed a unique index on the message_number specific to each chat.


### Creating composite foreign keys through Active Migration.
- I decided to specify the foreign key of the application model as the token rather than the id.  
  Similarly, for the chats table, I specified a composite foreign key (application_token, chat_number) rather than the id.

- ActiveRecord::Migration syntax doesn't support the creation of composite foreign keys, I had to customize it with raw SQL.  

### Creating has_many and belongs_to associations through composite foreign keys.

- Referencing a composite foreign key in the chats table was a bit unusual, Since ActiveRecord's associations by default don't support multi-column foreign key references.  

- **(implemented then discarded)** I customized the (chat has_many messages) association to guarantee that our queries utilize our index as a covering index.  
    (I left the implementation code commented out)  
    

- **(implemented then discarded)** I customized the (message belongs_to chat) association by defining a method that SELECTS the corresponding chat for the message using 'Chat.where'.  
  However, I wasn't satisfied with that as I didn't feel it was "Rails friendly".

- I found a cool gem I used that made it possible to create has_many and belongs_to association with composite foreign keys.
  [composite_primary_keys gem](https://github.com/composite-primary-keys/composite_primary_keys)
  
  
- **(To experiment later)** while searching for ways to implement a composite index via ActiveRecord, I stumbled upon this article: 
  [How to introduce composite primary keys in rails](https://shopify.engineering/how-to-introduce-composite-primary-keys-in-rails).  
  The article highlighted something I wasn't aware of. That is if I should use a composite primary key instead of a composite unique index.  
  
  After reading about the difference between a composite unique index and composite primary keys, 
  I learned that a composite primary key is faster because it is a clustered index.  
  However, I had to take into consideration the downside mentioned in the article (more expensive insertions).  
  
  So, there is a tradeoff here. Implementing a unique composite index to keep the insertion fast and give up extra reading performance,  
  or implementing a composite primary key for faster reading performance at the cost of slower insertions.  
  
  To decide on that, I think we need to analyze the nature of the application and see which is more frequent and important, reading or inserting.  
  I personally think that chat apps are read-write heavy. I could be wrong, I haven't witnessed such application on a large scale in action after all.  
  
  Therefore, I don't know which is more important, writing performance or reading performance.  
  I need to experiment with this later though to see how much performance improvement we can get on both sides.

### counters and race conditions.

- There are a couple of race conditions presented. 2 of them which are visible to me are:  
  - Multiple concurrent message creation requests could mess up the order of messages in the same chat.  
  - Multiple concurrent Chats and Messages creation requests could mess up the chats_counter/messages_counter values.  

  Based on the latter, two or more chats/messages being created with the same number and the same application_token would lead to an error due to the unique index constraint.  

  we need to handle each, so;  
  - We make a queue to handle the order of message/chat creation and also increment counters (Using Sidekiq).  
  - We ensure operation atomicity regarding the incrementing of counters (Using Redis INCR).
    
  that would help us avoid lost updates. That is when 2 requests attempt to increment the same value at the same time and only the last attempt is applied.  

- **(Not Implemented) -- Database auto_increment for chat_number/message_number.**  
    Thinking about the chat_number, message_number race condition, I wondered if I can just use MySQL's auto_increment on chat_number/message_number instead of having to risk wrong value insertion.  
    I searched for how to implement auto_increment on a secondary key of a composite index (chats_number in (app_token, chats_number) index).  
    I found a way that shows how to implement it in MySQL documentation.  [Mysql Example auto increment](https://dev.mysql.com/doc/refman/8.0/en/example-auto-increment.html)  
    
    However, I had to learn about the implications of using MyISAM DB Engine for the tables implementing that.  
    Most of what I have read has discouraged me from selecting that approach.  
    I have read about the limitations of MyISAM Engine regarding transactions, row-locking, and how it is not the default MySQL engine anymore.  
    
    So, I got a bit skeptical about it being the best choice, and I decided to stick with the caching option via REDIS.  

- **(Not Implemented) Incrementing Counter caches in queues when persisting objects to DB.**  
    I thought of incrementing the counters in the queue when persisting a chat/message at first for two reasons:  
    - Avoid the need for atomic increment operation since the queue would simulate the DB serializable isolation level.  
    - Have consistency between the number of current records persisted in DB and the actual counter value cached.  
    
    However, since we need to return the chat/message number immediately on creation requests,  
    we need the counters to count both the objects persisted to DB and the objects that are in memory and waiting in queue to be persisted in DB.  
    
    Updating our counters only when persisting to DB means that it doesn't count the objects in the queue waiting to be persisted, and that would cause inconsistency problems.  
    
    Therefore, we needed to increment the counters on creation even if the object has yet to be persisted to get the accurate message/chat number for the whole chats/messages (persisted + waiting in queue to be persisted).  

- **(Not Implemented) -- Rails counter cache.**  
    it would cause an overhead if we are executing a COUNT and update queries on the counters columns for each chat/message creation.  
    To minimize the number of SQL queries, we could batch process the counters columns in DB, so counter values don't have to be live in DB.  
    but also they shouldn’t be lagging more than 1 hour.  
    
    However, wouldn't it be better to make them live if it has little to no performance cost?  
    Especially if we have sacrificed the 'live' property of the values for performance improvement in the first place.  
    
    I remember reading about counter caching in Rails, so I went to check it out.  
    Comparing it to the Redis/sidekiq approach, it is a little more expensive in regards to writing queries, as it updates the counter with each insertion.  
    But, it doesn't query the count() of the table each time to update the parent table counter, it updates it from the cache just like Redis.  
    And it would also store the value counter in a cache, with no queries needed to get the value.  
    
    I don't know how the update query per insertion would affect the performance. But I thought it is simpler and would remove the layer of complexity of using Redis and sidekiq to achieve that.  
    However, I didn't go on with that as I have read it is slower compared to the Redis caching approach, and performance comes first.  

- **Scheduling a periodic update of counters to DB (Using Sidekiq-scheduler).**  
    I tried implementing the update using **ActiveRecords#update** for all applications but found it inefficient while observing the queries executed for the job.  
    It was an n+1 query problem and it got even worse with chats as its number is greater than that of apps.  
    
    Then I tried the **ActiveRecords#update_all** method to make it a single query and it worked.  
    
    Then I tried updating it with raw SQL. The performance gain with a few applications and chats was like 2x, despite although it executes the same query as ActiveRecords#update_all.  
    I don't know why executing the same query through the ORM was slower, I have got some ideas but I guess I'll investigate a bit more into that. I did it with raw SQL anyway.  
    I had the raw SQL insight from this article 
    [Proper Counter cache migrations in rails](http://ryan.mcgeary.org/2016/02/05/proper-counter-cache-migrations-in-rails)


- **(Not Implemented) Splitting queues. (I don't even know why I thought of it)**  
    I thought of splitting the creation of messages and chats into 2 separate queues where the work is distributed evenly among them.  
    Thankfully, I didn't. This would have presented a race condition where we could have tried to create a message for a chat that was not yet created.  
    
    I also thought of setting the priority to the chat creation queue to prevent that race condition.  
    Then I figured that there was no actual need for this as letting both of them in the same queue would perfectly preserve the dependency of messages and chats.  


### Searching messages using Elastic Search  
I haven't used elastic search before. I found a few gems integrating it in ruby. as I read about them and a couple of Stackoverflow posts on the topic,  
I settled with Searchkick as it is more Rails-friendly and also more popular according to [searchkick vs elasticsearch-rails](https://ruby.libhunt.com/compare-searchkick-vs-elasticsearch-rails.)

